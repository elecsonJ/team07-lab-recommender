"""
ì„œìš¸ëŒ€ ì˜ëŒ€ ì—°êµ¬ì‹¤ ì¶”ì²œ ì›¹ì•± (Streamlit)
ë²¡í„° ì„ë² ë”© + GPT-4o-mini ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ
"""

import streamlit as st
import json
import numpy as np
import os
import pickle
from typing import List, Dict, Any, Tuple
from openai import AzureOpenAI
import time

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ”¬ ì„œìš¸ëŒ€ ì˜ëŒ€ ì—°êµ¬ì‹¤ ì¶”ì²œ",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

class LabRecommendationSystem:
    def __init__(self):
        self.professors_data = []
        self.professor_embeddings = []
        self.client = None
        self.embedding_model = "text-embedding-3-small"
        
    @st.cache_data
    def load_professor_data(_self):
        """êµìˆ˜ì§„ ë°ì´í„° ë¡œë“œ (ìºì‹œë¨)"""
        try:
            with open('professors_final_complete.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            _self.professors_data = data["êµìˆ˜ì§„"]
            return True, f"{len(_self.professors_data)}ëª… êµìˆ˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ"
        except FileNotFoundError:
            return False, "professors_final_complete.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            return False, f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
    
    @st.cache_data
    def load_embeddings(_self):
        """ì €ì¥ëœ ì„ë² ë”© ë²¡í„° ë¡œë“œ (ìºì‹œë¨)"""
        try:
            with open('professor_embeddings.pkl', 'rb') as f:
                embedding_data = pickle.load(f)
            
            _self.professor_embeddings = embedding_data["embeddings"]
            return True, f"{len(_self.professor_embeddings)}ê°œ ì„ë² ë”© ë²¡í„° ë¡œë“œ ì™„ë£Œ"
        except FileNotFoundError:
            return False, "professor_embeddings.pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì„ë² ë”©ì„ ìƒì„±í•´ì£¼ì„¸ìš”."
        except Exception as e:
            return False, f"ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {str(e)}"
    
    def init_openai_client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
            api_version = os.getenv("OPENAI_API_VERSION", "2024-12-01-preview")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT") or st.secrets.get("AZURE_OPENAI_ENDPOINT")
            
            if not api_key or not azure_endpoint:
                return False, "OpenAI API í‚¤ ë˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            self.client = AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=azure_endpoint
            )
            return True, "OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ"
        except Exception as e:
            return False, f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
    
    def create_professor_text_for_embedding(self, professor: Dict) -> str:
        """êµìˆ˜ ì •ë³´ë¥¼ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        parts = []
        
        # ê¸°ë³¸ì •ë³´
        name = professor["ê¸°ë³¸ì •ë³´"]["êµìˆ˜ì´ë¦„"]
        degree = professor["ê¸°ë³¸ì •ë³´"]["í•™ìœ„"]
        parts.append(f"êµìˆ˜ëª…: {name}, í•™ìœ„: {degree}")
        
        # ì—°êµ¬ì‹¤
        if professor["ì—°êµ¬ì‹¤"]["ì—°êµ¬ì‹¤ëª…"]:
            parts.append(f"ì—°êµ¬ì‹¤: {professor['ì—°êµ¬ì‹¤']['ì—°êµ¬ì‹¤ëª…']}")
        
        # ì—°êµ¬ë¶„ì•¼ (ê°€ì¥ ì¤‘ìš”!)
        if professor["ì—°êµ¬ë¶„ì•¼"]["í‚¤ì›Œë“œ"]:
            parts.append(f"ì—°êµ¬ë¶„ì•¼: {professor['ì—°êµ¬ë¶„ì•¼']['í‚¤ì›Œë“œ']}")
        
        if professor["ì—°êµ¬ë¶„ì•¼"]["ì„¤ëª…"]:
            description = professor["ì—°êµ¬ë¶„ì•¼"]["ì„¤ëª…"][:200]
            parts.append(f"ì—°êµ¬ì„¤ëª…: {description}")
        
        # ì—°êµ¬ì£¼ì œ
        if professor["ì—°êµ¬ì£¼ì œ"]:
            topics = " | ".join(professor["ì—°êµ¬ì£¼ì œ"][:5])
            parts.append(f"ì—°êµ¬ì£¼ì œ: {topics}")
        
        # ê¸°ìˆ ë°©ë²•
        if professor["ê¸°ìˆ ë°ë°©ë²•"]:
            methods = " | ".join(professor["ê¸°ìˆ ë°ë°©ë²•"][:5])
            parts.append(f"ê¸°ìˆ ë°©ë²•: {methods}")
        
        # ë…¼ë¬¸ (ìµœì‹  3í¸ë§Œ)
        if professor["ë…¼ë¬¸"]:
            papers = " | ".join([paper[:100] for paper in professor["ë…¼ë¬¸"][:3]])
            parts.append(f"ìµœê·¼ë…¼ë¬¸: {papers}")
        
        return " / ".join(parts)
    
    def get_query_embedding(self, query: str) -> List[float]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ì˜ ì„ë² ë”© ë²¡í„° ìƒì„±"""
        try:
            response = self.client.embeddings.create(
                model=self.embedding_model,
                input=query
            )
            return response.data[0].embedding
        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return [0.0] * 1536
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)
        
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return float(dot_product / (norm1 * norm2))
    
    def find_similar_professors(self, query: str, top_k: int = 5) -> List[Tuple[Dict, float]]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ êµìˆ˜ë“¤ ì°¾ê¸°"""
        if not self.client:
            st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.get_query_embedding(query)
        
        # ëª¨ë“  êµìˆ˜ì™€ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for i, prof_embedding in enumerate(self.professor_embeddings):
            similarity = self.cosine_similarity(query_embedding, prof_embedding)
            similarities.append((self.professors_data[i], similarity))
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:top_k]
    
    def generate_recommendation_with_gpt(self, query: str, similar_professors: List[Tuple[Dict, float]]) -> str:
        """GPT-4o-minië¡œ ìµœì¢… ì¶”ì²œ ìƒì„±"""
        if not self.client:
            return "OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # ìƒìœ„ ë§¤ì¹­ëœ êµìˆ˜ë“¤ë§Œ GPTì—ê²Œ ì „ì†¡
        top_professors = []
        for prof, similarity in similar_professors:
            prof_summary = {
                "ì´ë¦„": prof["ê¸°ë³¸ì •ë³´"]["êµìˆ˜ì´ë¦„"],
                "ì—°êµ¬ì‹¤": prof["ì—°êµ¬ì‹¤"]["ì—°êµ¬ì‹¤ëª…"],
                "í‚¤ì›Œë“œ": prof["ì—°êµ¬ë¶„ì•¼"]["í‚¤ì›Œë“œ"][:150],  # í† í° ì ˆì•½
                "ì—°êµ¬ì£¼ì œ": prof["ì—°êµ¬ì£¼ì œ"][:3],
                "ê¸°ìˆ ë°©ë²•": prof["ê¸°ìˆ ë°ë°©ë²•"][:3],
                "ì´ë©”ì¼": prof["ê¸°ë³¸ì •ë³´"]["ì´ë©”ì¼"],
                "ë…¼ë¬¸ìˆ˜": len(prof["ë…¼ë¬¸"]),
                "ìœ ì‚¬ë„": f"{similarity:.3f}"
            }
            top_professors.append(prof_summary)
        
        prompt = f"""## ì„œìš¸ëŒ€í•™êµ ì˜ê³¼ëŒ€í•™ ì—°êµ¬ì‹¤ ì¶”ì²œ

**í•™ìƒ ì§ˆë¬¸:** {query}

**ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë§¤ì¹­ëœ ìƒìœ„ êµìˆ˜ì§„:**
{json.dumps(top_professors, ensure_ascii=False, indent=2)}

**ìš”ì²­ì‚¬í•­:**
ìœ„ í•™ìƒì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ì—°êµ¬ì‹¤ì„ ìˆœìœ„ë³„ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”.

**ë‹µë³€ í˜•ì‹:**
### ğŸ¥‡ 1ìˆœìœ„: [êµìˆ˜ëª…] êµìˆ˜ - [ì—°êµ¬ì‹¤ëª…]
- **ë§¤ì¹­ë„:** [ìœ ì‚¬ë„ ì ìˆ˜] (ë§¤ìš° ë†’ìŒ/ë†’ìŒ/ë³´í†µ)
- **ì¶”ì²œ ì´ìœ :** [ì™œ ì´ ì—°êµ¬ì‹¤ì´ ê°€ì¥ ì í•©í•œì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]
- **ì—°êµ¬ ë¶„ì•¼:** [ê´€ë ¨ í‚¤ì›Œë“œ]
- **ì—°ë½ì²˜:** [ì´ë©”ì¼]

### ğŸ¥ˆ 2ìˆœìœ„: [êµìˆ˜ëª…] êµìˆ˜ - [ì—°êµ¬ì‹¤ëª…]
- **ë§¤ì¹­ë„:** [ìœ ì‚¬ë„ ì ìˆ˜]
- **ì¶”ì²œ ì´ìœ :** [êµ¬ì²´ì ì¸ ë§¤ì¹­ ì´ìœ ]
- **ì—°êµ¬ ë¶„ì•¼:** [ê´€ë ¨ í‚¤ì›Œë“œ]
- **ì—°ë½ì²˜:** [ì´ë©”ì¼]

### ğŸ¥‰ 3ìˆœìœ„: [êµìˆ˜ëª…] êµìˆ˜ - [ì—°êµ¬ì‹¤ëª…]
- **ë§¤ì¹­ë„:** [ìœ ì‚¬ë„ ì ìˆ˜]
- **ì¶”ì²œ ì´ìœ :** [êµ¬ì²´ì ì¸ ë§¤ì¹­ ì´ìœ ]
- **ì—°êµ¬ ë¶„ì•¼:** [ê´€ë ¨ í‚¤ì›Œë“œ]
- **ì—°ë½ì²˜:** [ì´ë©”ì¼]

**ğŸ’¡ ì¶”ê°€ ì¡°ì–¸:** [í•´ë‹¹ ë¶„ì•¼ ì—°êµ¬ë¥¼ ìœ„í•œ ì‹¤ìš©ì ì¸ ì¡°ì–¸]"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì„œìš¸ëŒ€í•™êµ ì˜ê³¼ëŒ€í•™ ì—°êµ¬ì‹¤ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë§¤ì¹­ëœ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì—ê²Œ ìµœì ì˜ ì—°êµ¬ì‹¤ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”. ì¶”ì²œ ì´ìœ ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=1200
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def main():
    # í—¤ë”
    st.title("ğŸ”¬ ì„œìš¸ëŒ€í•™êµ ì˜ê³¼ëŒ€í•™ ì—°êµ¬ì‹¤ ì¶”ì²œ ì‹œìŠ¤í…œ")
    st.markdown("**ë²¡í„° ì„ë² ë”© + GPT-4o-mini ê¸°ë°˜ ë§ì¶¤í˜• ì—°êµ¬ì‹¤ ì¶”ì²œ**")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    @st.cache_resource
    def init_system():
        return LabRecommendationSystem()
    
    recommender = init_system()
    
    # ì‚¬ì´ë“œë°” - ì‹œìŠ¤í…œ ìƒíƒœ
    with st.sidebar:
        st.header("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # ë°ì´í„° ë¡œë“œ ìƒíƒœ
        data_success, data_msg = recommender.load_professor_data()
        if data_success:
            st.success(data_msg)
        else:
            st.error(data_msg)
            st.stop()
        
        # ì„ë² ë”© ë¡œë“œ ìƒíƒœ  
        embed_success, embed_msg = recommender.load_embeddings()
        if embed_success:
            st.success(embed_msg)
        else:
            st.warning(embed_msg)
            st.info("ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ
        if embed_success:  # ì„ë² ë”©ì´ ìˆì„ ë•Œë§Œ OpenAI ì´ˆê¸°í™”
            openai_success, openai_msg = recommender.init_openai_client()
            if openai_success:
                st.success(openai_msg)
            else:
                st.error(openai_msg)
                st.info("í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” Streamlit secretsì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        st.markdown("---")
        st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
        st.markdown(f"- **êµìˆ˜ ìˆ˜**: {len(recommender.professors_data)}ëª…")
        st.markdown(f"- **ì„ë² ë”© ëª¨ë¸**: text-embedding-3-small")
        st.markdown(f"- **ì¶”ì²œ ëª¨ë¸**: GPT-4o-mini")
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([2, 3])
    
    with col1:
        st.header("ğŸ’¬ ì—°êµ¬ ê´€ì‹¬ë¶„ì•¼ ì…ë ¥")
        
        # ì˜ˆì‹œ ì¿¼ë¦¬ ë²„íŠ¼ë“¤
        st.markdown("**ë¹ ë¥¸ ì˜ˆì‹œ:**")
        example_queries = [
            "ì•” ì¹˜ë£Œì™€ ê´€ë ¨ëœ ë‚˜ë…¸ê¸°ìˆ  ì—°êµ¬ì— ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤",
            "ë‡Œê³¼í•™ê³¼ ì¸ê³µì§€ëŠ¥ì„ ê²°í•©í•œ ì—°êµ¬ë¥¼ í•˜ê³  ì‹¶ì–´ìš”",
            "ë©´ì—­í•™ê³¼ ì„¸í¬ìƒë¬¼í•™ ë¶„ì•¼ì—ì„œ ì—°êµ¬í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤",
            "ì˜ìƒì˜í•™ê³¼ ì§„ë‹¨ê¸°ìˆ  ê°œë°œì— ê´€ì‹¬ìˆì–´ìš”"
        ]
        
        selected_example = None
        cols = st.columns(2)
        for i, example in enumerate(example_queries):
            with cols[i % 2]:
                if st.button(f"ì˜ˆì‹œ {i+1}", key=f"example_{i}"):
                    selected_example = example
        
        # ì‚¬ìš©ì ì…ë ¥
        user_query = st.text_area(
            "ê´€ì‹¬ìˆëŠ” ì—°êµ¬ë¶„ì•¼ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:",
            value=selected_example if selected_example else "",
            height=150,
            placeholder="ì˜ˆ: ì•” ì§„ë‹¨ì„ ìœ„í•œ ë‚˜ë…¸ì…ì ê¸°ë°˜ ì˜ìƒ ê¸°ìˆ ì— ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ PET/CTë¥¼ ì´ìš©í•œ ë¶„ìì˜ìƒ ë¶„ì•¼ì—ì„œ ì—°êµ¬í•˜ê³  ì‹¶ì–´ìš”."
        )
        
        # ì¶”ì²œ ì˜µì…˜
        st.markdown("### âš™ï¸ ì¶”ì²œ ì˜µì…˜")
        top_k = st.slider("ì¶”ì²œë°›ì„ ì—°êµ¬ì‹¤ ìˆ˜", min_value=3, max_value=7, value=5)
        
        # ì¶”ì²œ ì‹¤í–‰ ë²„íŠ¼
        recommend_button = st.button("ğŸ¯ ì—°êµ¬ì‹¤ ì¶”ì²œë°›ê¸°", type="primary", use_container_width=True)
    
    with col2:
        st.header("ğŸ“‹ ì¶”ì²œ ê²°ê³¼")
        
        if recommend_button and user_query.strip():
            if not embed_success:
                st.error("ì„ë² ë”© ë°ì´í„°ê°€ ì—†ì–´ ì¶”ì²œì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                with st.spinner("ğŸ” ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° ì¤‘..."):
                    # ë²¡í„° ë§¤ì¹­
                    similar_professors = recommender.find_similar_professors(user_query, top_k)
                    
                    if similar_professors:
                        # ë§¤ì¹­ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                        st.markdown("### ğŸ¯ ë²¡í„° ë§¤ì¹­ ê²°ê³¼")
                        match_df_data = []
                        for i, (prof, similarity) in enumerate(similar_professors, 1):
                            match_df_data.append({
                                "ìˆœìœ„": i,
                                "êµìˆ˜ëª…": prof["ê¸°ë³¸ì •ë³´"]["êµìˆ˜ì´ë¦„"],
                                "ìœ ì‚¬ë„": f"{similarity:.3f}",
                                "ì—°êµ¬ë¶„ì•¼": prof["ì—°êµ¬ë¶„ì•¼"]["í‚¤ì›Œë“œ"][:50] + "..." if len(prof["ì—°êµ¬ë¶„ì•¼"]["í‚¤ì›Œë“œ"]) > 50 else prof["ì—°êµ¬ë¶„ì•¼"]["í‚¤ì›Œë“œ"]
                            })
                        
                        st.dataframe(match_df_data, use_container_width=True)
                        
                        # GPT ì¶”ì²œ ìƒì„±
                        if recommender.client:
                            with st.spinner("ğŸ¤– GPT-4o-miniê°€ ìƒì„¸ ì¶”ì²œ ìƒì„± ì¤‘..."):
                                recommendation = recommender.generate_recommendation_with_gpt(user_query, similar_professors)
                                
                                st.markdown("### ğŸ“ AI ì¶”ì²œ ê²°ê³¼")
                                st.markdown(recommendation)
                        else:
                            st.warning("OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë²¡í„° ë§¤ì¹­ ê²°ê³¼ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
                    else:
                        st.error("ë§¤ì¹­ëœ ì—°êµ¬ì‹¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        elif recommend_button:
            st.warning("ì—°êµ¬ ê´€ì‹¬ë¶„ì•¼ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        else:
            st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ê´€ì‹¬ìˆëŠ” ì—°êµ¬ë¶„ì•¼ë¥¼ ì…ë ¥í•˜ê³  'ì—°êµ¬ì‹¤ ì¶”ì²œë°›ê¸°' ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”.")
            
            # ì‹œìŠ¤í…œ ì†Œê°œ
            st.markdown("### ğŸš€ ì‹œìŠ¤í…œ íŠ¹ì§•")
            st.markdown("""
            - **ë²¡í„° ì„ë² ë”©**: text-embedding-3-smallìœ¼ë¡œ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê³„ì‚°
            - **AI ì¶”ì²œ**: GPT-4o-miniê°€ êµ¬ì²´ì ì¸ ì¶”ì²œ ì´ìœ  ì œê³µ  
            - **ì‹¤ì‹œê°„ ë§¤ì¹­**: 31ëª… êµìˆ˜ì§„ ì¤‘ ìµœì  ë§¤ì¹­
            - **ì™„ì „í•œ ì •ë³´**: ì—°êµ¬ë¶„ì•¼, ì£¼ì œ, ê¸°ìˆ , ìµœì‹  ë…¼ë¬¸ í¬í•¨
            """)

if __name__ == "__main__":
    main()